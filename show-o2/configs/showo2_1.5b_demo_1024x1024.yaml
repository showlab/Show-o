wandb:
  entity: null
#  run_id: blvqij6q
  resume: 'auto'

experiment:
    project: "demo"
    name: "Showo2"
    output_dir: "Showo2_1024x1024_t2i"

model:
    weight_type: "bfloat16"
    vae_model:
        type: "wan21"
        pretrained_model_path: "Wan2.1_VAE.pth"

    showo:
        model_name: "Showo2"
        load_from_showo: True
        pretrained_model_path: "showlab/show-o2-1.5B-HQ"
        llm_model_path: "Qwen/Qwen2.5-1.5B-Instruct"
        llm_vocab_size: null # will be updated when setting the tokenizer in other code files
        hidden_size: 1536
        image_latent_dim: 16
        image_latent_height: 64
        image_latent_width: 64
        video_latent_height: 27
        video_latent_width: 27
        patch_size: 2
        add_time_embeds: True
        num_und_trans_layers: 8
        num_refiner_layers: 10
        clip_latent_dim: 1152
        add_qk_norm: True
    clip:
        pretrained_model_path: "google/siglip-so400m-patch14-384"
    gradient_checkpointing: True

dataset:
    params:
        validation_prompts_file: "prompts/paper_prompts.txt"
    preprocessing:
        max_seq_length: 4352
        resolution: 1024
        num_image_tokens: 4096
        num_video_tokens: 3645
        latent_height: ${model.showo.image_latent_height}
        latent_width: ${model.showo.image_latent_width}
        video_latent_height: ${model.showo.video_latent_height}
        video_latent_width: ${model.showo.video_latent_width}

transport:
    path_type: "Linear"
    prediction: "velocity"
    loss_weight: null
    train_eps: null
    sample_eps: null
    snr_type: "lognorm"
    sampling_method: "euler"
    guidance_scale: 5.0
    num_inference_steps: 20
    atol: 1e-6
    rtol: 1e-3
    reverse: False
    do_shift: True
    time_shifting_factor: 3.0

