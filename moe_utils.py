"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è MoE –≤ –º–æ–¥–µ–ª—å Show-o
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –ø–∞—Ç—á–∏–Ω–≥–∞ –∏ –æ–±—É—á–µ–Ω–∏—è

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    from moe_utils import patch_and_freeze_moe
    
    model = Showo.from_pretrained("showlab/show-o-w-clip-vit")
    model = patch_and_freeze_moe(model, num_experts=4, top_k=2)
"""

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
import io
import base64
import logging
import tempfile
import os
import mlflow
from models.phi import PhiMLP, PhiConfig
from models.moe_gates.gshard_gate import GShardGate
from collections import defaultdict
from typing import List, Dict, Optional


logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
STATS_TYPES = ['max_abs', 'min_abs', 'var']


class Stats:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π"""
    def __init__(self, device: str = "cpu"):
        self._lists: Dict[str, List[torch.Tensor]] = {name: [] for name in STATS_TYPES}
        self.device = device

    def append(self, name: str, tensor: torch.Tensor) -> None:
        if name not in self._lists:
            raise KeyError(f"Unknown stat name '{name}'")
        self._lists[name].append(tensor.detach().to('cpu'))

    def append_many(self, stats: Dict[str, torch.Tensor]) -> None:
        for k, v in stats.items():
            if v is None:
                continue
            self.append(k, v)

    @torch.no_grad()
    def collect_from_tensor(self, out: torch.Tensor) -> None:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ç–µ–Ω–∑–æ—Ä–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π"""
        max_abs = out.abs().amax(dim=1, keepdim=False)           # (batch_size,)
        var = out.var(dim=1, unbiased=False, keepdim=False)      # (batch_size,)
        min_abs = out.abs().amin(dim=1, keepdim=False)   
        
        self.append("max_abs", max_abs)
        self.append("var", var)
        self.append("min_abs", min_abs)

    def cat(self, name: str) -> Optional[torch.Tensor]:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Ç–µ–Ω–∑–æ—Ä—ã –¥–ª—è –¥–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        lst = self._lists.get(name)
        if not lst:
            return None
        return torch.cat(lst, dim=0)
    
    def clear(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        for k in list(self._lists.keys()):
            self._lists[k].clear()

    def __repr__(self):
        s = ", ".join(f"{k}: {len(v)}" for k, v in self._lists.items())
        return f"Stats({s})"


class SmallPhiMLP(nn.Module):
    """–£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π PhiMLP –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ MoE"""
    def __init__(self, config: PhiConfig, scale_factor: int = 4):
        super().__init__()
        self.config = config
        small_intermediate_size = config.intermediate_size // scale_factor
        if config.hidden_act == "gelu_new":
            self.activation_fn = torch.nn.functional.gelu
        else:
            self.activation_fn = getattr(torch.nn.functional, config.hidden_act)
        self.fc1 = nn.Linear(config.hidden_size, small_intermediate_size)
        self.fc2 = nn.Linear(small_intermediate_size, config.hidden_size)

    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        hidden_states = self.fc1(hidden_states)
        hidden_states = self.activation_fn(hidden_states)
        hidden_states = self.fc2(hidden_states)
        return hidden_states


class MoE(nn.Module):
    """Mixture of Experts —Å–ª–æ–π"""
    def __init__(self, num_experts, hidden_size, top_k, config: PhiConfig):
        super().__init__()
        self.gate = GShardGate(hidden_size, num_experts, 1, top_k)
        self.num_experts = num_experts
        self.hidden_size = hidden_size
        self.top_k = top_k
        self.experts = nn.ModuleList([SmallPhiMLP(config, scale_factor=4) for _ in range(self.num_experts)])
        self.alpha = nn.Parameter(torch.randn(self.num_experts))
        self._step_count = 0
        self._log_frequency = 10  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
        self._global_step = 0  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —à–∞–≥ –¥–ª—è MLflow
        self._layer_id = None  # ID —Å–ª–æ—è –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        self._soi_id = None  # Start of Image
        self._eoi_id = None  # End of Image
        self._sov_id = None  # Start of Video
        self._eov_id = None  # End of Video

    def forward(self, hidden_states, input_ids=None):
        batch_size, seq_len, hidden_size = hidden_states.shape
        hidden_states_flat = hidden_states.view(-1, hidden_size)
        gate_idx, gate_score = self.gate(hidden_states_flat)
        self._step_count += 1
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–µ–π—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏)
        # print(f'step_log_frequency: count: {self._step_count}, {self._log_frequency}')
        should_log = (self._step_count % self._log_frequency == 0)
        if hasattr(self, '_log_gates') and self._log_gates and should_log:
            print(f'logging gates')
            self._log_gate_distribution(gate_idx, gate_score, input_ids)
        
        output_flat = torch.zeros_like(hidden_states_flat)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º zeros_like –≤–º–µ—Å—Ç–æ zeros
        expert_stats = {}
        
        for k in range(self.top_k):
            expert_indices = gate_idx[:, k]
            weights = gate_score[:, k]
            for expert_id in range(self.num_experts):
                mask = expert_indices == expert_id
                if mask.any():
                    expert_input = hidden_states_flat[mask]
                    expert_output = self.experts[expert_id](expert_input)
                    weight = weights[mask] * self.alpha[expert_id]
                    output_flat[mask] += expert_output * weight.unsqueeze(-1)
                    
                    if hasattr(self, '_log_activations') and self._log_activations and should_log:
                        input_abs = torch.abs(expert_input)
                        output_abs = torch.abs(expert_output)
                        
                        expert_stats[expert_id] = {
                            'input_min': expert_input.min().item(),
                            'input_max': expert_input.max().item(),
                            'input_mean': expert_input.mean().item(),
                            'input_abs_min': input_abs.min().item(),
                            'input_abs_max': input_abs.max().item(),
                            'input_abs_mean': input_abs.mean().item(),
                            'output_min': expert_output.min().item(),
                            'output_max': expert_output.max().item(),
                            'output_mean': expert_output.mean().item(),
                            'output_abs_min': output_abs.min().item(),
                            'output_abs_max': output_abs.max().item(),
                            'output_abs_mean': output_abs.mean().item(),
                            'weight_min': weight.min().item(),
                            'weight_max': weight.max().item(),
                            'weight_mean': weight.mean().item(),
                            'alpha': self.alpha[expert_id].item(),
                            'num_tokens': mask.sum().item()
                        }
                    del expert_input, expert_output, weight
        if hasattr(self, '_log_activations') and self._log_activations and should_log and expert_stats:
            self._log_activation_stats(expert_stats)
        
        result = output_flat.view(batch_size, seq_len, hidden_size)
        del output_flat, hidden_states_flat, gate_idx, gate_score
        return result

    def _log_gate_distribution(self, gate_idx, gate_score, input_ids=None):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–µ–π—Ç–æ–≤ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º"""
        import logging
        logger = logging.getLogger(__name__)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤
        modality = self._get_token_modality(input_ids.view(-1) if input_ids is not None else None)
        
        # –û–±—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–µ–π—Ç–æ–≤
        expert_counts = {}
        for expert_id in range(self.num_experts):
            count = (gate_idx == expert_id).sum().item()
            expert_counts[expert_id] = count
        
        total_activations = sum(expert_counts.values())
        if total_activations > 0:
            self._log_to_mlflow_gates(expert_counts, total_activations, gate_score)
            if modality is not None:
                self._log_modality_specific_gates(gate_idx, gate_score, modality)
    
    def _log_modality_specific_gates(self, gate_idx, gate_score, modality):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–µ–π—Ç–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏"""
        import logging
        logger = logging.getLogger(__name__)
        text_mask = (modality == 0)
        image_mask = (modality == 1)
        video_mask = (modality == 2)
        
        modalities = [
            ("text", text_mask),
            ("image", image_mask),
            ("video", video_mask)
        ]
        
        for modality_name, mask in modalities:
            if mask.any():
                modality_gate_idx = gate_idx[mask]
                modality_gate_score = gate_score[mask]
                expert_counts = {}
                for expert_id in range(self.num_experts):
                    count = (modality_gate_idx == expert_id).sum().item()
                    expert_counts[expert_id] = count
                
                total_activations = sum(expert_counts.values())
                if total_activations > 0:
                    self._log_to_mlflow_modality_gates(expert_counts, total_activations, modality_gate_score, modality_name)

    def _log_activation_stats(self, expert_stats):
        self._log_to_mlflow_activations(expert_stats)

    def enable_logging(self, log_gates=True, log_activations=True, log_frequency=10):
        self._log_gates = log_gates
        self._log_activations = log_activations
        self._log_frequency = log_frequency

    def set_global_step(self, global_step):
        self._global_step = global_step

    def set_layer_id(self, layer_id):
        self._layer_id = layer_id
    
    def set_special_tokens(self, soi_id=None, eoi_id=None, sov_id=None, eov_id=None):
        self._soi_id = soi_id
        self._eoi_id = eoi_id
        self._sov_id = sov_id
        self._eov_id = eov_id
    
    def _get_token_modality(self, input_ids_flat):
        if input_ids_flat is None or self._soi_id is None or self._eoi_id is None:
            return None
        modality = torch.zeros(input_ids_flat.shape[0], dtype=torch.long, device=input_ids_flat.device)
        soi_positions = (input_ids_flat == self._soi_id).nonzero(as_tuple=True)[0]
        eoi_positions = (input_ids_flat == self._eoi_id).nonzero(as_tuple=True)[0]
        for soi_pos, eoi_pos in zip(soi_positions, eoi_positions):
            if soi_pos < eoi_pos:
                modality[soi_pos:eoi_pos+1] = 1  # 1 = image tokens
        if self._sov_id is not None and self._eov_id is not None:
            sov_positions = (input_ids_flat == self._sov_id).nonzero(as_tuple=True)[0]
            eov_positions = (input_ids_flat == self._eov_id).nonzero(as_tuple=True)[0]
            
            for sov_pos, eov_pos in zip(sov_positions, eov_positions):
                if sov_pos < eov_pos:
                    modality[sov_pos:eov_pos+1] = 2  # 2 = video tokens
        
        return modality

    def _create_gate_histogram(self, gate_score):
        """–°–æ–∑–¥–∞–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–µ–π—Ç–æ–≤"""
        plt.figure(figsize=(10, 6))
        gate_weights = gate_score.detach().cpu().numpy().flatten()
        plt.hist(gate_weights, bins=50, alpha=0.7, color='blue', edgecolor='black')
        plt.title(f'Gate Weights Distribution (Overall) - Layer {self._layer_id} - Step {self._global_step}')
        plt.xlabel('Gate Weight Value')
        plt.ylabel('Frequency')
        plt.grid(True, alpha=0.3)
        
        mean_val = np.mean(gate_weights)
        std_val = np.std(gate_weights)
        plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.4f}')
        plt.axvline(mean_val + std_val, color='orange', linestyle=':', label=f'+1œÉ: {mean_val + std_val:.4f}')
        plt.axvline(mean_val - std_val, color='orange', linestyle=':', label=f'-1œÉ: {mean_val - std_val:.4f}')
        plt.legend()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return buf.getvalue()
    
    def _log_to_mlflow_gates(self, expert_counts, total_activations, gate_score):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≥–µ–π—Ç–æ–≤ –≤ MLflow"""
        import tempfile
        import os
        import mlflow
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π client –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            if hasattr(self, '_mlflow_client') and hasattr(self, '_mlflow_run_id'):
                client = self._mlflow_client
                run_id = self._mlflow_run_id
            else:
                from mlflow.tracking import MlflowClient
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π run_id
                run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None
                if run_id is None:
                    return
                
                client = MlflowClient()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–ª–æ—è
            layer_prefix = f"moe/layer_{self._layer_id}"
            
            # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            expert_balance = max(expert_counts.values()) - min(expert_counts.values()) if expert_counts else 0
            client.log_metric(run_id, f"{layer_prefix}/expert_balance", expert_balance, step=self._global_step)
            client.log_metric(run_id, f"{layer_prefix}/total_activations", total_activations, step=self._global_step)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤
            client.log_metric(run_id, f"{layer_prefix}/gate_weights_mean", gate_score.mean().item(), step=self._global_step)
            client.log_metric(run_id, f"{layer_prefix}/gate_weights_std", gate_score.std().item(), step=self._global_step)
            
            # –û–±—â–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤–µ—Å–æ–≤ –≥–µ–π—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–∞ - –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ
            
            # –°–æ–∑–¥–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            expert_histogram_bytes = self._create_expert_activation_histogram(expert_counts)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            try:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
                temp_dir = tempfile.mkdtemp()
                tmp_file_path = os.path.join(temp_dir, f"expert_token_counts_step_{self._global_step}.png")
                
                with open(tmp_file_path, 'wb') as f:
                    f.write(expert_histogram_bytes)
                
                client.log_artifact(run_id, tmp_file_path, layer_prefix)
                print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {layer_prefix}/expert_token_counts_step_{self._global_step}.png")
            except Exception as artifact_error:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {artifact_error}")
                # Fallback: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
                artifacts_dir = f"./mlruns/artifacts/{layer_prefix}"
                os.makedirs(artifacts_dir, exist_ok=True)
                local_path = f"{artifacts_dir}/expert_activations_histogram_step_{self._global_step}.png"
                with open(local_path, 'wb') as f:
                    f.write(expert_histogram_bytes)
                print(f"üìä –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ: {local_path}")
            finally:
                os.unlink(tmp_file_path)
                os.rmdir(temp_dir)
            
        except Exception as e:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MLflow, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ
            print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã: {e}")
    
    def _log_to_mlflow_modality_gates(self, expert_counts, total_activations, gate_score, modality_name):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≥–µ–π—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ MLflow"""
        import tempfile
        import os
        import mlflow
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π client –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            if hasattr(self, '_mlflow_client') and hasattr(self, '_mlflow_run_id'):
                client = self._mlflow_client
                run_id = self._mlflow_run_id
            else:
                from mlflow.tracking import MlflowClient
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π run_id
                run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None
                if run_id is None:
                    return
                
                client = MlflowClient()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            layer_prefix = f"moe/layer_{self._layer_id}/{modality_name}"
            
            # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            expert_balance = max(expert_counts.values()) - min(expert_counts.values()) if expert_counts else 0
            client.log_metric(run_id, f"{layer_prefix}/expert_balance", expert_balance, step=self._global_step)
            client.log_metric(run_id, f"{layer_prefix}/total_activations", total_activations, step=self._global_step)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            client.log_metric(run_id, f"{layer_prefix}/gate_weights_mean", gate_score.mean().item(), step=self._global_step)
            client.log_metric(run_id, f"{layer_prefix}/gate_weights_std", gate_score.std().item(), step=self._global_step)
            
            # –°–æ–∑–¥–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            histogram_bytes = self._create_modality_histogram(gate_score, modality_name)
            
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
            temp_dir = tempfile.mkdtemp()
            tmp_file_path = os.path.join(temp_dir, f"gate_distribution_{modality_name}_step_{self._global_step}.png")
            
            with open(tmp_file_path, 'wb') as f:
                f.write(histogram_bytes)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ MLflow client (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞)
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º client.log_artifact —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø—É—Ç–µ–º (–±–µ–∑ –∫–æ—Å–æ–π —á–µ—Ä—Ç—ã –≤ –∫–æ–Ω—Ü–µ)
                client.log_artifact(run_id, tmp_file_path, layer_prefix)
                print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–µ–π—Ç–æ–≤ {modality_name} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {layer_prefix}/gate_distribution_{modality_name}_step_{self._global_step}.png")
            except Exception as artifact_error:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ client.log_artifact: {artifact_error}")
                # Fallback: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
                artifacts_dir = f"./mlruns/artifacts/{layer_prefix}"
                os.makedirs(artifacts_dir, exist_ok=True)
                local_path = f"{artifacts_dir}/gate_weights_histogram_step_{self._global_step}.png"
                with open(local_path, 'wb') as f:
                    f.write(histogram_bytes)
                print(f"üìä –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ: {local_path}")
            finally:
                os.unlink(tmp_file_path)
                os.rmdir(temp_dir)
            
            # –°–æ–∑–¥–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            expert_histogram_bytes = self._create_expert_activation_histogram(expert_counts)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            try:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
                temp_dir = tempfile.mkdtemp()
                tmp_file_path = os.path.join(temp_dir, f"expert_token_counts_{modality_name}_step_{self._global_step}.png")
                
                with open(tmp_file_path, 'wb') as f:
                    f.write(expert_histogram_bytes)
                
                client.log_artifact(run_id, tmp_file_path, layer_prefix)
                print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º {modality_name} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {layer_prefix}/expert_token_counts_{modality_name}_step_{self._global_step}.png")
            except Exception as artifact_error:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ {modality_name}: {artifact_error}")
                # Fallback: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
                artifacts_dir = f"./mlruns/artifacts/{layer_prefix}"
                os.makedirs(artifacts_dir, exist_ok=True)
                local_path = f"{artifacts_dir}/expert_token_counts_{modality_name}_step_{self._global_step}.png"
                with open(local_path, 'wb') as f:
                    f.write(expert_histogram_bytes)
                print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º {modality_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ: {local_path}")
            finally:
                os.unlink(tmp_file_path)
                os.rmdir(temp_dir)
            
        except Exception as e:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MLflow, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ
            print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def _create_modality_histogram(self, gate_score, modality_name):
        """–°–æ–∑–¥–∞–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–µ–π—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏"""
        plt.figure(figsize=(10, 6))
        
        # –°–æ–∑–¥–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –≤–µ—Å–æ–≤ –≥–µ–π—Ç–æ–≤
        gate_weights = gate_score.detach().cpu().numpy().flatten()
        
        plt.hist(gate_weights, bins=50, alpha=0.7, color='blue', edgecolor='black')
        plt.title(f'Gate Distribution - Layer {self._layer_id} - {modality_name.capitalize()} Tokens - Step {self._global_step}')
        plt.xlabel('Gate Weight Value')
        plt.ylabel('Frequency')
        plt.grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫
        mean_val = np.mean(gate_weights)
        std_val = np.std(gate_weights)
        plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.4f}')
        plt.axvline(mean_val + std_val, color='orange', linestyle=':', label=f'+1œÉ: {mean_val + std_val:.4f}')
        plt.axvline(mean_val - std_val, color='orange', linestyle=':', label=f'-1œÉ: {mean_val - std_val:.4f}')
        plt.legend()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return buf.getvalue()

    def _log_to_mlflow_activations(self, expert_stats):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤ MLflow"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π client –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            if hasattr(self, '_mlflow_client') and hasattr(self, '_mlflow_run_id'):
                client = self._mlflow_client
                run_id = self._mlflow_run_id
            else:
                import mlflow
                from mlflow.tracking import MlflowClient
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π run_id
                run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None
                if run_id is None:
                    return
                
                client = MlflowClient()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
            layer_prefix = f"moe/layer_{self._layer_id}"
            
            if expert_stats:
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
                for expert_id, stats in expert_stats.items():
                    expert_prefix = f"{layer_prefix}/expert_{expert_id}"
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ü–∏–π
                    client.log_metric(run_id, f"{expert_prefix}/input_min", stats['input_min'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/input_max", stats['input_max'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/input_mean", stats['input_mean'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/input_abs_min", stats['input_abs_min'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/input_abs_max", stats['input_abs_max'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/input_abs_mean", stats['input_abs_mean'], step=self._global_step)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ü–∏–π
                    client.log_metric(run_id, f"{expert_prefix}/output_min", stats['output_min'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/output_max", stats['output_max'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/output_mean", stats['output_mean'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/output_abs_min", stats['output_abs_min'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/output_abs_max", stats['output_abs_max'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/output_abs_mean", stats['output_abs_mean'], step=self._global_step)
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    client.log_metric(run_id, f"{expert_prefix}/alpha", stats['alpha'], step=self._global_step)
                    client.log_metric(run_id, f"{expert_prefix}/num_tokens", stats['num_tokens'], step=self._global_step)
                
                # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞–º
                all_input_mins = [stats['input_min'] for stats in expert_stats.values()]
                all_input_maxs = [stats['input_max'] for stats in expert_stats.values()]
                all_output_mins = [stats['output_min'] for stats in expert_stats.values()]
                all_output_maxs = [stats['output_max'] for stats in expert_stats.values()]
                all_input_abs_mins = [stats['input_abs_min'] for stats in expert_stats.values()]
                all_input_abs_maxs = [stats['input_abs_max'] for stats in expert_stats.values()]
                all_output_abs_mins = [stats['output_abs_min'] for stats in expert_stats.values()]
                all_output_abs_maxs = [stats['output_abs_max'] for stats in expert_stats.values()]
                all_alphas = [stats['alpha'] for stats in expert_stats.values()]
                all_tokens = [stats['num_tokens'] for stats in expert_stats.values()]
                
                # –õ–æ–≥–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                client.log_metric(run_id, f"{layer_prefix}/input_range", max(all_input_maxs) - min(all_input_mins), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/output_range", max(all_output_maxs) - min(all_output_mins), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/input_abs_range", max(all_input_abs_maxs) - min(all_input_abs_mins), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/output_abs_range", max(all_output_abs_maxs) - min(all_output_abs_mins), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/alpha_mean", sum(all_alphas) / len(all_alphas), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/total_tokens", sum(all_tokens), step=self._global_step)
                client.log_metric(run_id, f"{layer_prefix}/active_experts", len(expert_stats), step=self._global_step)
            
        except Exception as e:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MLflow, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ
            pass

    def _create_expert_activation_histogram(self, expert_counts):
        """–°–æ–∑–¥–∞–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤ = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)"""
        plt.figure(figsize=(10, 6))
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        experts = list(expert_counts.keys())
        activations = list(expert_counts.values())
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–æ–ª–±—á–∞—Ç—É—é –¥–∏–∞–≥—Ä–∞–º–º—É
        bars = plt.bar(experts, activations, alpha=0.7, color='green', edgecolor='black')
        plt.title(f'Expert Token Counts - Layer {self._layer_id} - Step {self._global_step}')
        plt.xlabel('Expert ID')
        plt.ylabel('Number of Activations')
        plt.grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, count in zip(bars, activations):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    str(count), ha='center', va='bottom')
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_activations = sum(activations)
        balance = max(activations) - min(activations) if activations else 0
        plt.text(0.02, 0.98, f'Total: {total_activations}\nBalance: {balance}', 
                transform=plt.gca().transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return buf.getvalue()


def patch_model_with_moe(model, count_layers_to_patch=3, num_experts=4, top_k=2, special_tokens=None):
    """
    –ó–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ MLP —Å–ª–æ–∏ –Ω–∞ MoE
    
    Args:
        model: Show-o –º–æ–¥–µ–ª—å
        num_experts: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        top_k: —Å–∫–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        special_tokens: —Å–ª–æ–≤–∞—Ä—å —Å ID —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    
    Returns:
        model —Å MoE —Å–ª–æ—è–º–∏
    """
    print(f"üîß –ü–∞—Ç—á–∏–º –º–æ–¥–µ–ª—å —Å MoE (experts={num_experts}, top_k={top_k})...")
    config_phi = model.showo.config
    
    for layer_idx, layer in list(enumerate(model.showo.model.layers))[::-1]:
        if count_layers_to_patch == 0:
            break
        if hasattr(layer, 'mlp'):
            print(f"  ‚Üí –°–ª–æ–π {layer_idx}")
            moe_layer = MoE(
                num_experts=num_experts,
                hidden_size=config_phi.hidden_size,
                top_k=top_k,
                config=config_phi
            )
            # –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è MoE —Å–ª–æ—è (–∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤)
            moe_layer.enable_logging(log_gates=True, log_activations=True, log_frequency=50)
            moe_layer.set_layer_id(layer_idx)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ID —Å–ª–æ—è
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏
            if special_tokens is not None:
                moe_layer.set_special_tokens(
                    soi_id=special_tokens.get('soi_id'),
                    eoi_id=special_tokens.get('eoi_id'),
                    sov_id=special_tokens.get('sov_id'),
                    eov_id=special_tokens.get('eov_id')
                )
            
            layer.mlp = moe_layer
            count_layers_to_patch -= 1
    
    print("‚úì –ü–∞—Ç—á–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
    return model


def freeze_non_moe_params(model):
    print("‚ùÑÔ∏è  –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–æ–º–µ MoE...")

    for param in model.parameters():
        param.requires_grad = False
    
    # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ MoE
    trainable_params = 0
    total_params = 0
    moe_param_names = []
    
    for name, param in model.named_parameters():
        total_params += param.numel()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ MoE –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–µ—Å—Ç—å experts, gate, alpha - —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è MoE)
        if 'showo.model.layers' in name and 'mlp' in name:
            if any(x in name for x in ['mlp.experts', 'mlp.gate', 'mlp.alpha']):
                param.requires_grad = True
                trainable_params += param.numel()
                moe_param_names.append(name)
    
    print(f"‚úì –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,} total, {trainable_params:,} trainable ({100*trainable_params/total_params:.1f}%)")
    if len(moe_param_names) > 0:
        print(f"‚úì –†–∞–∑–º–æ—Ä–æ–∂–µ–Ω–æ {len(moe_param_names)} MoE –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:")
        for name in moe_param_names[:5]:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"    - {name}")
        if len(moe_param_names) > 5:
            print(f"    ... –∏ –µ—â–µ {len(moe_param_names) - 5}")
    return model


def patch_and_freeze_moe(model, count_layers_to_patch=3, num_experts=4, top_k=2, mlflow_client=None, mlflow_run_id=None, special_tokens=None):
    model = patch_model_with_moe(model, count_layers_to_patch, num_experts, top_k, special_tokens)
    if mlflow_client is not None and mlflow_run_id is not None:
        for layer in model.showo.model.layers:
            if hasattr(layer, 'mlp') and hasattr(layer.mlp, 'experts'):
                layer.mlp._mlflow_client = mlflow_client
                layer.mlp._mlflow_run_id = mlflow_run_id
    
    model = freeze_non_moe_params(model)
    return model


def save_moe_weights(model, path):
    moe_state = {
        k: v for k, v in model.state_dict().items() 
        if any(x in k for x in ['mlp.experts', 'mlp.gate', 'mlp.alpha'])
    }
    torch.save(moe_state, path)
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(moe_state)} MoE –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ {path}")


def load_moe_weights(model, path):
    moe_weights = torch.load(path)
    model.load_state_dict(moe_weights, strict=False)
    print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(moe_weights)} MoE –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ {path}")
    return model


def get_activations(recorder, stat: str = "max_abs", layers: list[int] = None):
    """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å–ª–æ–µ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    if stat not in STATS_TYPES:
        raise ValueError(f"stat must be one of {STATS_TYPES}, got {stat}")
    if layers is None:
        layers = list(range(24))
    layer_names = []
    acts_list = []

    for ind in layers:
        layer_name = f"showo.model.layers.{ind}.mlp.fc2"
        if layer_name not in recorder.outputs:
            continue

        stats_obj: Stats = recorder.outputs[layer_name]
        t = stats_obj.cat(stat)
        if t is None:
            continue

        t = t.detach().cpu().flatten()
        if t.numel() == 0:
            continue

        layer_names.append(layer_name)
        acts_list.append(t)

    return layer_names, acts_list


def create_stats_boxplots(recorder, stat: str = "max_abs", layers: list[int] = None,
                         figsize=(14,6), showfliers=False):
    """–°–æ–∑–¥–∞–µ—Ç boxplot –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π"""
    layer_names, acts_list = get_activations(recorder, stat=stat, layers=layers)

    if len(acts_list) == 0:
        print("No activations collected for the requested layers/stat.")
        return None

    data = [a.numpy() if isinstance(a, torch.Tensor) else np.asarray(a) for a in acts_list]
    plt.figure(figsize=figsize)
    labels = [ln.split(".")[3] if len(ln.split(".")) > 3 else ln for ln in layer_names]
    plt.boxplot(data, labels=labels, showfliers=showfliers)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel(stat)
    plt.title(f"Boxplots of '{stat}' across layers ({len(data)} layers)")
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    plt.close()
    
    return buf.getvalue()


def create_all_stats_boxplots(recorder, layers: list[int] = None, figsize=(18,6), showfliers=False):
    """–°–æ–∑–¥–∞–µ—Ç –≤—Å–µ boxplot'—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫"""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
    if not isinstance(recorder, dict):
        recorders = {'': recorder}
    else:
        recorders = recorder
    
    stats = list(STATS_TYPES)
    n_stats = len(stats)
    n_recorders = len(recorders)
    
    # 2 —Å—Ç—Ä–æ–∫–∏: boxplots –∏ —Å—Ä–µ–¥–Ω–∏–µ
    fig, axes = plt.subplots(2, n_stats, figsize=(figsize[0], figsize[1] * 1.5), sharey=False)
    if n_stats == 1:
        axes = axes.reshape(-1, 1)
    
    colors = plt.cm.Set2(range(n_recorders))
    
    for col, stat in enumerate(stats):
        ax_box = axes[0, col]
        ax_mean = axes[1, col]
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –≤—Å–µ—Ö —Ä–µ–∫–æ—Ä–¥–µ—Ä–æ–≤
        recorders_data = {}
        layer_names_all = None
        
        for rec_name, rec in recorders.items():
            layer_names, acts_list = get_activations(rec, stat=stat, layers=layers)
            if len(acts_list) == 0:
                continue
            
            if layer_names_all is None:
                layer_names_all = layer_names
            
            data = [a.numpy() if isinstance(a, torch.Tensor) else np.asarray(a) for a in acts_list]
            recorders_data[rec_name] = data
        
        if len(recorders_data) == 0:
            ax_box.text(0.5, 0.5, f"No data", ha='center', va='center')
            ax_box.set_title(stat)
            ax_mean.text(0.5, 0.5, f"No data", ha='center', va='center')
            continue
        
        # === –í–ï–†–•–ù–ò–ô –†–Ø–î: Boxplots ===
        n_layers = len(next(iter(recorders_data.values())))
        width = 0.8 / n_recorders
        
        legend_patches = []
        for i, (rec_name, data) in enumerate(recorders_data.items()):
            positions = [j + 1 + (i - n_recorders/2 + 0.5) * width for j in range(n_layers)]
            bp = ax_box.boxplot(data, positions=positions, widths=width*0.9, 
                               showfliers=showfliers, patch_artist=True)
            for patch in bp['boxes']:
                patch.set_facecolor(colors[i])
            
            if rec_name:
                from matplotlib.patches import Patch
                legend_patches.append(Patch(facecolor=colors[i], label=rec_name))
        
        labels = [ln.split(".")[3] if len(ln.split("."))>3 else ln for ln in layer_names_all]
        ax_box.set_xticks(range(1, n_layers + 1))
        ax_box.set_xticklabels(labels, rotation=45, ha='right')
        ax_box.set_title(stat)
        
        if len(legend_patches) > 0:
            ax_box.legend(handles=legend_patches)
        for i, (rec_name, data) in enumerate(recorders_data.items()):
            means = [d.mean() for d in data]
            x = range(1, len(means) + 1)
            ax_mean.plot(x, means, marker='o', color=colors[i], 
                        label=rec_name if rec_name else None)
        
        ax_mean.set_xticks(range(1, n_layers + 1))
        ax_mean.set_xticklabels(labels, rotation=45, ha='right')
        ax_mean.set_ylabel("Mean")
        ax_mean.grid(True, alpha=0.3)
        
        if len(legend_patches) > 0:
            ax_mean.legend()
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    plt.close()
    
    return buf.getvalue()


class LayerOutputRecorder:
    """–†–µ–∫–æ—Ä–¥–µ—Ä –¥–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –∏–∑ —Å–ª–æ–µ–≤ –º–æ–¥–µ–ª–∏"""
    def __init__(self, device='cuda'):
        self.outputs = defaultdict(lambda: Stats(device=device))
        self.inputs_shapes = defaultdict(list)
        self.handles = []
        self.device = device

    def build_hook_fn(self, name):
        def hook_fn(module, input_, output):
            with torch.no_grad():
                out = output.detach()
                self.outputs[name].collect_from_tensor(out)
                self.inputs_shapes[name].append(input_[0].shape)
        return hook_fn

    def register_hook(self, module_name, module):
        handle = module.register_forward_hook(self.build_hook_fn(module_name))
        self.handles.append(handle)

    def register_hooks(self, modules: list[tuple[str, torch.nn.Module]]) -> None:
        for module_name, module in modules:
            self.register_hook(module_name, module)

    def remove_hooks(self):
        for handle in self.handles:
            handle.remove()
        self.handles = []

    def clear(self):
        for stats in self.outputs.values():
            stats.clear()
        self.outputs.clear()
        self.inputs_shapes.clear()
        torch.cuda.empty_cache()


def log_stats_to_mlflow(recorder, mlflow_client, run_id, step, layer_prefix="activations"):
    """–õ–æ–≥–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤ MLflow"""
    try:
        # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π –≥—Ä–∞—Ñ–∏–∫ –≤—Å–µ—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        all_stats_bytes = create_all_stats_boxplots(recorder)
        
        if all_stats_bytes:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_dir = tempfile.mkdtemp()
            tmp_file_path = os.path.join(temp_dir, f"all_stats_step_{step}.png")
            
            with open(tmp_file_path, 'wb') as f:
                f.write(all_stats_bytes)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤ MLflow
            mlflow_client.log_artifact(run_id, tmp_file_path, layer_prefix)
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã: {layer_prefix}/all_stats_step_{step}.png")
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(tmp_file_path)
            os.rmdir(temp_dir)
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫: {e}")


if __name__ == "__main__":
    from models import Showo
    model = Showo.from_pretrained("showlab/show-o-w-clip-vit")
    model = patch_and_freeze_moe(model, num_experts=4, top_k=2)

    print("\n–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å.")
    print("–ü—Ä–∏–º–µ—Ä:")
    print("  optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)")

