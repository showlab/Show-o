{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abe8ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ['CUDA_HOME'] = '/home/jovyan/vasiliev/notebooks/Show-o/cuda_fake'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1816123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from models import Showo\n",
    "from training.prompting_utils import UniversalPrompting, create_attention_mask_predict_next\n",
    "from training.utils import get_config\n",
    "import json\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from models.clip_encoder import CLIPVisionTower\n",
    "from transformers import CLIPImageProcessor\n",
    "from llava.llava import conversation as conversation_lib\n",
    "from omegaconf import OmegaConf\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "conversation_lib.default_conversation = conversation_lib.conv_templates[\"phi1.5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_mmu import run_mmu\n",
    "from inference_t2i import run_t2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f2f6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('configs/showo_demo_w_clip_vit_512x512.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31cc1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    model = Showo.from_pretrained(config.model.showo.pretrained_model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09d05990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerOutputRecorder:\n",
    "    def __init__(self, device='cuda', compute_stats=True):\n",
    "        self.outputs = defaultdict(list)\n",
    "        self.inputs_shapes = defaultdict(list)\n",
    "        self.handles = []\n",
    "        self.device = device\n",
    "        self.compute_stats = compute_stats\n",
    "\n",
    "    def build_hook_fn(self, name):\n",
    "        def hook_fn(module, input_, output):\n",
    "            with torch.no_grad():\n",
    "                if self.compute_stats:\n",
    "                    stats = {\n",
    "                        'max_abs': output.detach().abs().max(dim=1, keepdim=False).values[0].to('cpu'),\n",
    "                        # 'mean': output.mean(dim=-1),\n",
    "                        # 'shape': output.shape\n",
    "                    }\n",
    "                    if self.device == 'cpu':\n",
    "                        stats = {k: v.cpu() if isinstance(v, torch.Tensor) else v \n",
    "                                for k, v in stats.items()}\n",
    "                    self.outputs[name].append(stats)\n",
    "                else:\n",
    "                    self.outputs[name].append(output.detach())\n",
    "                    \n",
    "                self.inputs_shapes[name].append(input_[0].shape)\n",
    "        return hook_fn\n",
    "\n",
    "    def register_hook(self, module_name, module):\n",
    "        handle = module.register_forward_hook(self.build_hook_fn(module_name))\n",
    "        self.handles.append(handle)\n",
    "\n",
    "    def register_hooks(self, modules: list[tuple[str, torch.nn.Module]]) -> None:\n",
    "        for module_name, module in modules:\n",
    "            self.register_hook(module_name, module)\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        self.handles = []\n",
    "        \n",
    "    def clear(self):\n",
    "        self.outputs.clear()\n",
    "        self.inputs_shapes.clear()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46ecaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_layers(model) -> list[tuple[str, torch.nn.Module]]:\n",
    "    layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            layers.append((name, module))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e64bbb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'mask_token_id': 58497} were passed to Showo, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "/home/jovyan/vasiliev/notebooks/Show-o/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention implementation:  sdpa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/vasiliev/notebooks/Show-o/models/modeling_showo.py:49: FutureWarning: Accessing config attribute `w_clip_vit` directly via 'Showo' object attribute is deprecated. Please access 'w_clip_vit' over 'Showo's config object instead, e.g. 'unet.config.w_clip_vit'.\n",
      "  if self.w_clip_vit:\n",
      "The config attributes {'mask_token_id': 58497} were passed to Showo, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention implementation:  sdpa\n"
     ]
    }
   ],
   "source": [
    "model_t2i = get_model(config)\n",
    "model_mmu = get_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebb3a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  Showo(\n",
       "    (showo): PhiForCausalLM(\n",
       "      (model): PhiModel(\n",
       "        (embed_tokens): Embedding(58498, 2048)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x PhiDecoderLayer(\n",
       "            (self_attn): PhiSdpaAttention(\n",
       "              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (rotary_emb): PhiRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): PhiMLP(\n",
       "              (activation_fn): NewGELUActivation()\n",
       "              (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=58498, bias=True)\n",
       "    )\n",
       "    (mm_projector): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "  )),\n",
       " ('showo',\n",
       "  PhiForCausalLM(\n",
       "    (model): PhiModel(\n",
       "      (embed_tokens): Embedding(58498, 2048)\n",
       "      (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x PhiDecoderLayer(\n",
       "          (self_attn): PhiSdpaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (rotary_emb): PhiRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): PhiMLP(\n",
       "            (activation_fn): NewGELUActivation()\n",
       "            (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "            (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          )\n",
       "          (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=58498, bias=True)\n",
       "  )),\n",
       " ('showo.model',\n",
       "  PhiModel(\n",
       "    (embed_tokens): Embedding(58498, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )),\n",
       " ('showo.model.embed_tokens', Embedding(58498, 2048)),\n",
       " ('showo.model.embed_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers',\n",
       "  ModuleList(\n",
       "    (0-23): 24 x PhiDecoderLayer(\n",
       "      (self_attn): PhiSdpaAttention(\n",
       "        (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): PhiRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): PhiMLP(\n",
       "        (activation_fn): NewGELUActivation()\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "      )\n",
       "      (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('showo.model.layers.0',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.0.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.0.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.0.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.0.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.0.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.0.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.0.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.0.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.0.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.0.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.0.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.0.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.0.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.0.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.1',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.1.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.1.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.1.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.1.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.1.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.1.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.1.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.1.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.1.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.1.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.1.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.1.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.1.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.1.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.2',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.2.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.2.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.2.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.2.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.2.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.2.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.2.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.2.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.2.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.2.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.2.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.2.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.2.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.2.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.3',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.3.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.3.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.3.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.3.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.3.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.3.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.3.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.3.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.3.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.3.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.3.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.3.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.3.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.3.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.4',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.4.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.4.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.4.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.4.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.4.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.4.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.4.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.4.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.4.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.4.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.4.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.4.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.4.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.4.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.5',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.5.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.5.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.5.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.5.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.5.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.5.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.5.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.5.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.5.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.5.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.5.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.5.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.5.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.5.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.6',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.6.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.6.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.6.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.6.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.6.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.6.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.6.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.6.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.6.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.6.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.6.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.6.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.6.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.6.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.7',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.7.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.7.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.7.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.7.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.7.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.7.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.7.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.7.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.7.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.7.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.7.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.7.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.7.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.7.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.8',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.8.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.8.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.8.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.8.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.8.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.8.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.8.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.8.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.8.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.8.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.8.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.8.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.8.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.8.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.9',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.9.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.9.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.9.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.9.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.9.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.9.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.9.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.9.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.9.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.9.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.9.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.9.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.9.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.9.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.10',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.10.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.10.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.10.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.10.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.10.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.10.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.10.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.10.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.10.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.10.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.10.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.10.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.10.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.10.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.11',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.11.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.11.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.11.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.11.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.11.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.11.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.11.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.11.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.11.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.11.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.11.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.11.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.11.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.11.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.12',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.12.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.12.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.12.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.12.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.12.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.12.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.12.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.12.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.12.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.12.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.12.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.12.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.12.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.12.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.13',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.13.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.13.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.13.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.13.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.13.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.13.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.13.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.13.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.13.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.13.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.13.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.13.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.13.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.13.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.14',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.14.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.14.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.14.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.14.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.14.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.14.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.14.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.14.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.14.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.14.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.14.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.14.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.14.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.14.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.15',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.15.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.15.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.15.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.15.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.15.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.15.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.15.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.15.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.15.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.15.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.15.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.15.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.15.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.15.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.16',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.16.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.16.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.16.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.16.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.16.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.16.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.16.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.16.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.16.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.16.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.16.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.16.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.16.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.16.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.17',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.17.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.17.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.17.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.17.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.17.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.17.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.17.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.17.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.17.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.17.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.17.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.17.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.17.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.17.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.18',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.18.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.18.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.18.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.18.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.18.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.18.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.18.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.18.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.18.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.18.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.18.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.18.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.18.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.18.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.19',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.19.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.19.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.19.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.19.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.19.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.19.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.19.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.19.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.19.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.19.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.19.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.19.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.19.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.19.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.20',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.20.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.20.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.20.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.20.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.20.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.20.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.20.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.20.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.20.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.20.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.20.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.20.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.20.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.20.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.21',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.21.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.21.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.21.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.21.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.21.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.21.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.21.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.21.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.21.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.21.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.21.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.21.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.21.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.21.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.22',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.22.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.22.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.22.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.22.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.22.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.22.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.22.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.22.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.22.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.22.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.22.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.22.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.22.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.22.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.layers.23',\n",
       "  PhiDecoderLayer(\n",
       "    (self_attn): PhiSdpaAttention(\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary_emb): PhiRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): PhiMLP(\n",
       "      (activation_fn): NewGELUActivation()\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "    )\n",
       "    (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('showo.model.layers.23.self_attn',\n",
       "  PhiSdpaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (q_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (k_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): PhiRotaryEmbedding()\n",
       "  )),\n",
       " ('showo.model.layers.23.self_attn.q_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.23.self_attn.k_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.23.self_attn.v_proj',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.23.self_attn.dense',\n",
       "  Linear(in_features=2048, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.23.self_attn.q_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.23.self_attn.k_layernorm',\n",
       "  LayerNorm((64,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.23.self_attn.rotary_emb', PhiRotaryEmbedding()),\n",
       " ('showo.model.layers.23.mlp',\n",
       "  PhiMLP(\n",
       "    (activation_fn): NewGELUActivation()\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('showo.model.layers.23.mlp.activation_fn', NewGELUActivation()),\n",
       " ('showo.model.layers.23.mlp.fc1',\n",
       "  Linear(in_features=2048, out_features=8192, bias=True)),\n",
       " ('showo.model.layers.23.mlp.fc2',\n",
       "  Linear(in_features=8192, out_features=2048, bias=True)),\n",
       " ('showo.model.layers.23.input_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.model.layers.23.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('showo.model.final_layernorm',\n",
       "  LayerNorm((2048,), eps=1e-05, elementwise_affine=True)),\n",
       " ('showo.lm_head', Linear(in_features=2048, out_features=58498, bias=True)),\n",
       " ('mm_projector',\n",
       "  Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  )),\n",
       " ('mm_projector.0', Linear(in_features=1024, out_features=2048, bias=True)),\n",
       " ('mm_projector.1', GELU(approximate='none')),\n",
       " ('mm_projector.2', Linear(in_features=2048, out_features=2048, bias=True))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_mmu.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "477a2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers_t2i = get_target_layers(model_t2i)\n",
    "activations_recorder_t2i = LayerOutputRecorder()\n",
    "activations_recorder_t2i.register_hooks(target_layers_t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ef9c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers_mmu = get_target_layers(model_mmu)\n",
    "activations_recorder_mmu = LayerOutputRecorder()\n",
    "activations_recorder_mmu.register_hooks(target_layers_mmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a4ccc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode=t2i dataset.params.validation_prompts_file=validation_prompts/showoprompts.txt batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab9370ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv run inference_t2i.py config=configs/showo_demo_w_clip_vit_512x512.yaml mode=t2i dataset.params.validation_prompts_file=validation_prompts/showoprompts.txt batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54a4aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv run inference_mmu.py config=configs/showo_demo_w_clip_vit_512x512.yaml max_new_tokens=100 mmu_image_root=./mmu_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1018206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"configs/showo_demo_w_clip_vit_512x512.yaml\")\n",
    "# cfg.batch_size = 1\n",
    "cfg.max_new_tokens = 100\n",
    "\n",
    "cfg_mmu = deepcopy(cfg)\n",
    "cfg_t2i = deepcopy(cfg)\n",
    "\n",
    "\n",
    "cfg_t2i.dataset.params.validation_prompts_file=\"validation_prompts/text2image_prompts.txt\"\n",
    "cfg_t2i.mode = \"t2i\"\n",
    "cfg_mmu.mmu_image_root = \"./mmu_validation\"\n",
    "cfg_mmu.device = \"cuda:0\"\n",
    "cfg_t2i.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd95c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 13, 16, 16) = 3328 dimensions.\n",
      "Look-up free quantizer with codebook size: 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/jovyan/vasiliev/notebooks/Show-o/inference_mmu.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids).to(device).squeeze(0)\n",
      " 17%|        | 1/6 [00:01<00:09,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The path or structure is on a set of train tracks that are surrounded by trees and rocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 2/6 [00:09<00:21,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The scene appears to be surreal, as it is not a typical representation of a living room or a beach setting. Instead, it features a couch, a table, and a potted plant, all placed on a beach-like surface. The couch is positioned in the middle of the scene, and the table is located to the left of the couch. The potted plant is situated to the right of the couch. The combination of these elements creates an unusual and dreamlike atmosphere, as it is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 3/6 [00:14<00:15,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, it is interacting with something or someone in the image. A dog is standing in a field of flowers, sniffing a flower, and appears to be smelling it. This suggests that the dog is curious and interested in the flower, possibly exploring its surroundings or smelling it as a part of its natural behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 4/6 [00:15<00:07,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The time of day in the picture is during the day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 5/6 [00:16<00:02,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The character, Spongebob, appears to be expressing happiness or excitement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:18<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The cat is walking through the snow, moving across the snow-covered ground.\n",
      "=== Multimodal Understanding Results ===\n",
      "\n",
      "Image 1: dog.png\n",
      "Response: User: What kind of path or structure is it on?\n",
      " Answer :  The path or structure is on a set of train tracks that are surrounded by trees and rocks.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image 2: cat.png\n",
      "Response: User: Does the scene look realistic or surreal?\n",
      " Answer :  The scene appears to be surreal, as it is not a typical representation of a living room or a beach setting. Instead, it features a couch, a table, and a potted plant, all placed on a beach-like surface. The couch is positioned in the middle of the scene, and the table is located to the left of the couch. The potted plant is situated to the right of the couch. The combination of these elements creates an unusual and dreamlike atmosphere, as it is\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image 3: cat.txt\n",
      "Response: User: Is it interacting with something or someone?\n",
      " Answer :  Yes, it is interacting with something or someone in the image. A dog is standing in a field of flowers, sniffing a flower, and appears to be smelling it. This suggests that the dog is curious and interested in the flower, possibly exploring its surroundings or smelling it as a part of its natural behavior.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image 4: dog.txt\n",
      "Response: User: What is the time of day in the picture?\n",
      " Answer :  The time of day in the picture is during the day.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image 5: landscape.png\n",
      "Response: User: What emotion does the character seem to express?\n",
      " Answer :  The character, Spongebob, appears to be expressing happiness or excitement.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image 6: landscape.txt\n",
      "Response: User: What is the cat doing in the picture?\n",
      " Answer :  The cat is walking through the snow, moving across the snow-covered ground.\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_mmu(cfg_mmu, model_mmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "925fac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mm_projector.0', 'mm_projector.2', 'showo.model.layers.0.self_attn.q_proj', 'showo.model.layers.0.self_attn.k_proj', 'showo.model.layers.0.self_attn.v_proj', 'showo.model.layers.0.self_attn.dense', 'showo.model.layers.0.mlp.fc1', 'showo.model.layers.0.mlp.fc2', 'showo.model.layers.1.self_attn.q_proj', 'showo.model.layers.1.self_attn.k_proj', 'showo.model.layers.1.self_attn.v_proj', 'showo.model.layers.1.self_attn.dense', 'showo.model.layers.1.mlp.fc1', 'showo.model.layers.1.mlp.fc2', 'showo.model.layers.2.self_attn.q_proj', 'showo.model.layers.2.self_attn.k_proj', 'showo.model.layers.2.self_attn.v_proj', 'showo.model.layers.2.self_attn.dense', 'showo.model.layers.2.mlp.fc1', 'showo.model.layers.2.mlp.fc2', 'showo.model.layers.3.self_attn.q_proj', 'showo.model.layers.3.self_attn.k_proj', 'showo.model.layers.3.self_attn.v_proj', 'showo.model.layers.3.self_attn.dense', 'showo.model.layers.3.mlp.fc1', 'showo.model.layers.3.mlp.fc2', 'showo.model.layers.4.self_attn.q_proj', 'showo.model.layers.4.self_attn.k_proj', 'showo.model.layers.4.self_attn.v_proj', 'showo.model.layers.4.self_attn.dense', 'showo.model.layers.4.mlp.fc1', 'showo.model.layers.4.mlp.fc2', 'showo.model.layers.5.self_attn.q_proj', 'showo.model.layers.5.self_attn.k_proj', 'showo.model.layers.5.self_attn.v_proj', 'showo.model.layers.5.self_attn.dense', 'showo.model.layers.5.mlp.fc1', 'showo.model.layers.5.mlp.fc2', 'showo.model.layers.6.self_attn.q_proj', 'showo.model.layers.6.self_attn.k_proj', 'showo.model.layers.6.self_attn.v_proj', 'showo.model.layers.6.self_attn.dense', 'showo.model.layers.6.mlp.fc1', 'showo.model.layers.6.mlp.fc2', 'showo.model.layers.7.self_attn.q_proj', 'showo.model.layers.7.self_attn.k_proj', 'showo.model.layers.7.self_attn.v_proj', 'showo.model.layers.7.self_attn.dense', 'showo.model.layers.7.mlp.fc1', 'showo.model.layers.7.mlp.fc2', 'showo.model.layers.8.self_attn.q_proj', 'showo.model.layers.8.self_attn.k_proj', 'showo.model.layers.8.self_attn.v_proj', 'showo.model.layers.8.self_attn.dense', 'showo.model.layers.8.mlp.fc1', 'showo.model.layers.8.mlp.fc2', 'showo.model.layers.9.self_attn.q_proj', 'showo.model.layers.9.self_attn.k_proj', 'showo.model.layers.9.self_attn.v_proj', 'showo.model.layers.9.self_attn.dense', 'showo.model.layers.9.mlp.fc1', 'showo.model.layers.9.mlp.fc2', 'showo.model.layers.10.self_attn.q_proj', 'showo.model.layers.10.self_attn.k_proj', 'showo.model.layers.10.self_attn.v_proj', 'showo.model.layers.10.self_attn.dense', 'showo.model.layers.10.mlp.fc1', 'showo.model.layers.10.mlp.fc2', 'showo.model.layers.11.self_attn.q_proj', 'showo.model.layers.11.self_attn.k_proj', 'showo.model.layers.11.self_attn.v_proj', 'showo.model.layers.11.self_attn.dense', 'showo.model.layers.11.mlp.fc1', 'showo.model.layers.11.mlp.fc2', 'showo.model.layers.12.self_attn.q_proj', 'showo.model.layers.12.self_attn.k_proj', 'showo.model.layers.12.self_attn.v_proj', 'showo.model.layers.12.self_attn.dense', 'showo.model.layers.12.mlp.fc1', 'showo.model.layers.12.mlp.fc2', 'showo.model.layers.13.self_attn.q_proj', 'showo.model.layers.13.self_attn.k_proj', 'showo.model.layers.13.self_attn.v_proj', 'showo.model.layers.13.self_attn.dense', 'showo.model.layers.13.mlp.fc1', 'showo.model.layers.13.mlp.fc2', 'showo.model.layers.14.self_attn.q_proj', 'showo.model.layers.14.self_attn.k_proj', 'showo.model.layers.14.self_attn.v_proj', 'showo.model.layers.14.self_attn.dense', 'showo.model.layers.14.mlp.fc1', 'showo.model.layers.14.mlp.fc2', 'showo.model.layers.15.self_attn.q_proj', 'showo.model.layers.15.self_attn.k_proj', 'showo.model.layers.15.self_attn.v_proj', 'showo.model.layers.15.self_attn.dense', 'showo.model.layers.15.mlp.fc1', 'showo.model.layers.15.mlp.fc2', 'showo.model.layers.16.self_attn.q_proj', 'showo.model.layers.16.self_attn.k_proj', 'showo.model.layers.16.self_attn.v_proj', 'showo.model.layers.16.self_attn.dense', 'showo.model.layers.16.mlp.fc1', 'showo.model.layers.16.mlp.fc2', 'showo.model.layers.17.self_attn.q_proj', 'showo.model.layers.17.self_attn.k_proj', 'showo.model.layers.17.self_attn.v_proj', 'showo.model.layers.17.self_attn.dense', 'showo.model.layers.17.mlp.fc1', 'showo.model.layers.17.mlp.fc2', 'showo.model.layers.18.self_attn.q_proj', 'showo.model.layers.18.self_attn.k_proj', 'showo.model.layers.18.self_attn.v_proj', 'showo.model.layers.18.self_attn.dense', 'showo.model.layers.18.mlp.fc1', 'showo.model.layers.18.mlp.fc2', 'showo.model.layers.19.self_attn.q_proj', 'showo.model.layers.19.self_attn.k_proj', 'showo.model.layers.19.self_attn.v_proj', 'showo.model.layers.19.self_attn.dense', 'showo.model.layers.19.mlp.fc1', 'showo.model.layers.19.mlp.fc2', 'showo.model.layers.20.self_attn.q_proj', 'showo.model.layers.20.self_attn.k_proj', 'showo.model.layers.20.self_attn.v_proj', 'showo.model.layers.20.self_attn.dense', 'showo.model.layers.20.mlp.fc1', 'showo.model.layers.20.mlp.fc2', 'showo.model.layers.21.self_attn.q_proj', 'showo.model.layers.21.self_attn.k_proj', 'showo.model.layers.21.self_attn.v_proj', 'showo.model.layers.21.self_attn.dense', 'showo.model.layers.21.mlp.fc1', 'showo.model.layers.21.mlp.fc2', 'showo.model.layers.22.self_attn.q_proj', 'showo.model.layers.22.self_attn.k_proj', 'showo.model.layers.22.self_attn.v_proj', 'showo.model.layers.22.self_attn.dense', 'showo.model.layers.22.mlp.fc1', 'showo.model.layers.22.mlp.fc2', 'showo.model.layers.23.self_attn.q_proj', 'showo.model.layers.23.self_attn.k_proj', 'showo.model.layers.23.self_attn.v_proj', 'showo.model.layers.23.self_attn.dense', 'showo.model.layers.23.mlp.fc1', 'showo.model.layers.23.mlp.fc2', 'showo.lm_head'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_recorder_mmu.outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(recorder):\n",
    "    acts_list = []\n",
    "    for ind in tqdm(range(0, 24)):\n",
    "        layer_name = f'showo.model.layers.{ind}.mlp.fc2'\n",
    "        acts = [a['max_abs'] for a in recorder.outputs[layer_name]]\n",
    "\n",
    "        if len(acts) == 0:\n",
    "            break\n",
    "\n",
    "        acts_list.extend(acts)\n",
    "    tens = torch.concat(acts_list, dim=0)\n",
    "    # print(tens.shape)\n",
    "    return tens.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "828096d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_acts_boxplots(acts):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.boxplot(acts, labels=[f'Layer {i}' for i in range(len(acts))], showfliers=False)\n",
    "    plt.ylabel(\"Activation value\")\n",
    "    plt.title(\"Boxplots of activations for different layers\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fbbd0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 24/24 [00:00<00:00, 21063.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11304960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acts_mmu = get_activations(activations_recorder_mmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d70b406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4795)\n"
     ]
    }
   ],
   "source": [
    "print(acts_mmu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5c50be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images to: show-o-demo/inference_t2i_20251006_192525\n",
      "Working with z of shape (1, 13, 16, 16) = 3328 dimensions.\n",
      "Look-up free quantizer with codebook size: 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:24<00:00, 24.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 text-to-image results to show-o-demo/inference_t2i_20251006_192525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_t2i(cfg_t2i, model_t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "04c4acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 24/24 [00:00<00:00, 93379.68it/s]\n"
     ]
    }
   ],
   "source": [
    "acts_t2i = get_activations(activations_recorder_t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f96719a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0004,  0.4156,  1.0055,  ..., 13.3257, 15.9834, 11.6894])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_t2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28d800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5fa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf2e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b012cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f69f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Show-o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
